{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import arrow\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of notebook\n",
    "\n",
    "Here I'm going to take the one-day nc's that we've made, which are in:\n",
    "\n",
    "    /data/tjarniko/MEOPAR/analysis-tereza/notebooks/carbon_dev/For_Evie/HINDCAST_201905_ncs\n",
    "    \n",
    "and consolidate into timeseries ncs - so that instead of 365 ncs for a year, we have one. (I made the ncs individually because it's easier for the computer - the original files are really big and trying to write to a single dataset from all the original nc's for a given year never works).\n",
    "\n",
    "So this notebook literally just contains the consolidation code -for the 'prod' file variables - PPPHY, PPDIAT, and PPMRUB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### TJSJ Write a function that returns a list of paths to nc files for given days in a year - this time to the daily ncs we made in Part A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = '2016-01-01'\n",
    "end = '2016-12-31'\n",
    "tyr = '2016'\n",
    "desig = 'prod_' #could also be 'prod_ or ptrc_'\n",
    "verbose = False\n",
    "t_str = 'prod_timeseries_2016.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heck leap years!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def make_nclist(start,end,verbose):\n",
    "\n",
    "    nc_array = []\n",
    "    start_run = arrow.get(start)\n",
    "    end_run = arrow.get(end)\n",
    "    \n",
    "    \n",
    "    arrow_array = []\n",
    "    for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "        arrow_array.append(r)\n",
    "\n",
    "    dayslen = len(arrow_array)\n",
    "    \n",
    "    for i in range(0,dayslen):\n",
    "        tdate = arrow_array[i][0]\n",
    "        if verbose == True:\n",
    "            print('DATE IS: ' +str(tdate))\n",
    "        ddmmmyy = tdate.format('DDMMMYY').lower()\n",
    "        if verbose == True:\n",
    "            print('Arrow ddmmmyy format is: '+ str(ddmmmyy))\n",
    "            \n",
    "        t_nc = '/data/tjarniko/MEOPAR/analysis-tereza/' + \\\n",
    "        'notebooks/carbon_dev/For_Evie/HINDCAST_201905_ncs/FILES_' + tyr + \\\n",
    "        '/EVIE_PLACES_' + desig + (ddmmmyy) + '.nc'\n",
    "        t_ncname = glob.glob(t_nc)\n",
    "        if ddmmmyy == '29feb16':\n",
    "            print('heck leap years!')\n",
    "        if ddmmmyy != '29feb16':\n",
    "            nc_array.append(t_ncname[0])\n",
    "            if verbose == True:\n",
    "                print('file is: ' + t_ncname[0])\n",
    "                print('')\n",
    "            \n",
    "        \n",
    "    return nc_array\n",
    "\n",
    "nc_array = make_nclist(start,end,verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/tjarniko/MEOPAR/analysis-tereza/notebooks/carbon_dev/For_Evie/HINDCAST_201905_ncs/FILES_2016/EVIE_PLACES_prod_01jan16.nc\n"
     ]
    }
   ],
   "source": [
    "print(nc_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /Deep Bay:\n",
      "    dimensions(sizes): depths(40)\n",
      "    variables(dimensions): float32 \u001b[4mPPDIAT_timeseries\u001b[0m(depths), float32 \u001b[4mPPPHY_timeseries\u001b[0m(depths), float32 \u001b[4mPPMRUB_timeseries\u001b[0m(depths)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = nc.Dataset(nc_array[0])\n",
    "print(w['Deep Bay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TJSJ Make a dictionary again to store our data for each station, also a list of station names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLACES_withdat = {\n",
    "'Deep Bay': {\n",
    "'NEMO grid ji': (599, 126),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "\n",
    "},\n",
    "    \n",
    "'Southern Baynes': {\n",
    "'NEMO grid ji': (602, 127),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "\n",
    "},\n",
    "\n",
    "'Northern Baynes': {\n",
    "'NEMO grid ji': (646, 127),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Fanny Bay': {\n",
    "'NEMO grid ji': (614, 120),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Maple Bay': {\n",
    "'NEMO grid ji': (392, 213),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Salt Spring': {\n",
    "'NEMO grid ji': (386, 218),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Nanoose Bay': {\n",
    "'NEMO grid ji': (517, 190),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Lasqueti Island': {\n",
    "'NEMO grid ji': (586, 195),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Main SoG': {\n",
    "'NEMO grid ji': (450, 253),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Cortes/Marina': {\n",
    "'NEMO grid ji': (732, 157),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Lund/Desolation Sound': {\n",
    "'NEMO grid ji': (702, 187),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "'Mouth of Okeover': {\n",
    "'NEMO grid ji': (726, 192),\n",
    "    'PPDIAT_timeseries':np.zeros([40,365]),\n",
    "    'PPPHY_timeseries':np.zeros([40,365]),\n",
    "    'PPMRUB_timeseries':np.zeros([40,365]),\n",
    "    \n",
    "},\n",
    "\n",
    "}\n",
    "\n",
    "list_places = ['Deep Bay', 'Southern Baynes', 'Northern Baynes', \\\n",
    "               'Fanny Bay', 'Maple Bay', 'Salt Spring', 'Nanoose Bay',\\\n",
    "               'Lasqueti Island', 'Main SoG', 'Cortes/Marina', \\\n",
    "               'Lund/Desolation Sound', 'Mouth of Okeover']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TJSJ Open each dataset in array, put the data from the nc file (t_nc) to the dictionary (called PLACES_withdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,len(nc_array)):\n",
    "    t_nc = nc.Dataset(nc_array[i])\n",
    "    for s in range(0, len(list_places)):\n",
    "        t_place = list_places[s]\n",
    "        PLACES_withdat[t_place]['PPDIAT_timeseries'][:,i] = t_nc[t_place]['PPDIAT_timeseries'][:]\n",
    "        PLACES_withdat[t_place]['PPPHY_timeseries'][:,i] = t_nc[t_place]['PPPHY_timeseries'][:]\n",
    "        PLACES_withdat[t_place]['PPMRUB_timeseries'][:,i] = t_nc[t_place]['PPMRUB_timeseries'][:]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TJSJ as before, write all this to a consolidated .nc file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f = nc.Dataset(t_str, 'w')\n",
    "g = f.createGroup('Deep Bay')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Deep Bay']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Deep Bay']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Deep Bay']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Southern Baynes')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Southern Baynes']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Southern Baynes']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Southern Baynes']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Northern Baynes')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Northern Baynes']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Northern Baynes']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Northern Baynes']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Fanny Bay')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Fanny Bay']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Fanny Bay']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Fanny Bay']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Maple Bay')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Maple Bay']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Maple Bay']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Maple Bay']['PPMRUB_timeseries'][:]\n",
    "\n",
    "g = f.createGroup('Salt Spring')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Salt Spring']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Salt Spring']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Salt Spring']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Nanoose Bay')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Nanoose Bay']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Nanoose Bay']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Nanoose Bay']['PPMRUB_timeseries'][:]\n",
    "\n",
    "g = f.createGroup('Lasqueti Island')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Lasqueti Island']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Lasqueti Island']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Lasqueti Island']['PPMRUB_timeseries'][:]\n",
    "\n",
    "g = f.createGroup('Main SoG')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Main SoG']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Main SoG']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Main SoG']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Cortes/Marina')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Cortes/Marina']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Cortes/Marina']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Cortes/Marina']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Lund/Desolation Sound')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Lund/Desolation Sound']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Lund/Desolation Sound']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Lund/Desolation Sound']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "g = f.createGroup('Mouth of Okeover')\n",
    "g.createDimension('depths', 40)\n",
    "g.createDimension('days',365)\n",
    "ts = g.createVariable('PPPHY_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Mouth of Okeover']['PPPHY_timeseries'][:]\n",
    "ts = g.createVariable('PPDIAT_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Mouth of Okeover']['PPDIAT_timeseries'][:]\n",
    "ts = g.createVariable('PPMRUB_timeseries','f4',('depths','days'))\n",
    "ts[:] = PLACES_withdat['Mouth of Okeover']['PPMRUB_timeseries'][:]\n",
    "\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

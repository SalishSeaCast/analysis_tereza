{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('seaborn')\n",
    "import matplotlib.patches as patches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import netCDF4 as nc\n",
    "import cmocean as cm\n",
    "import numpy as np\n",
    "from salishsea_tools import (\n",
    "    viz_tools,\n",
    ")\n",
    "import sys\n",
    "sys.path.append('/data/tjarniko/mocsy')\n",
    "import mocsy\n",
    "\n",
    "sys.path.append('/data/tjarniko/mocsy')\n",
    "import arrow\n",
    "sys.path.append('/data/tjarniko/MEOPAR/analysis-tereza/notebooks/carbon_dev/BASE_RUN/CLEAN/CCCma_src')\n",
    "import mocsy\n",
    "import CCCma\n",
    "import CCCma_stations as cs\n",
    "import CCCma_fwk as Cfwk\n",
    "from matplotlib import reload\n",
    "import arrow\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find a month worth of profiles from a spot, average them in space, time, get std devs\n",
    "\n",
    "## do the same for the PI case\n",
    "\n",
    "## plot them\n",
    "\n",
    "\n",
    "    jan 1 - jan 31\n",
    "    march 1 - march 31\n",
    "    july 1-july 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Feb 01, 2015\n",
      "ANALYZING ANALYZING  Feb 02, 2015\n",
      "ANALYZING ANALYZING  Feb 03, 2015\n",
      "ANALYZING ANALYZING  Feb 04, 2015\n",
      "ANALYZING ANALYZING  Feb 05, 2015\n",
      "ANALYZING ANALYZING  Feb 06, 2015\n",
      "ANALYZING ANALYZING  Feb 07, 2015\n",
      "ANALYZING ANALYZING  Feb 08, 2015\n",
      "ANALYZING ANALYZING  Feb 09, 2015\n",
      "ANALYZING ANALYZING  Feb 10, 2015\n",
      "ANALYZING ANALYZING  Feb 11, 2015\n",
      "ANALYZING ANALYZING  Feb 12, 2015\n",
      "ANALYZING ANALYZING  Feb 13, 2015\n",
      "ANALYZING ANALYZING  Feb 14, 2015\n",
      "ANALYZING ANALYZING  Feb 15, 2015\n",
      "ANALYZING ANALYZING  Feb 16, 2015\n",
      "ANALYZING ANALYZING  Feb 17, 2015\n",
      "ANALYZING ANALYZING  Feb 18, 2015\n",
      "ANALYZING ANALYZING  Feb 19, 2015\n",
      "ANALYZING ANALYZING  Feb 20, 2015\n",
      "ANALYZING ANALYZING  Feb 21, 2015\n",
      "ANALYZING ANALYZING  Feb 22, 2015\n",
      "ANALYZING ANALYZING  Feb 23, 2015\n",
      "ANALYZING ANALYZING  Feb 24, 2015\n",
      "ANALYZING ANALYZING  Feb 25, 2015\n",
      "ANALYZING ANALYZING  Feb 26, 2015\n",
      "ANALYZING ANALYZING  Feb 27, 2015\n",
      "ANALYZING ANALYZING  Feb 28, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-02-01'\n",
    "end = '2015-02-28'\n",
    "f = nc.Dataset('./feb_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Mar 01, 2015\n",
      "ANALYZING ANALYZING  Mar 02, 2015\n",
      "ANALYZING ANALYZING  Mar 03, 2015\n",
      "ANALYZING ANALYZING  Mar 04, 2015\n",
      "ANALYZING ANALYZING  Mar 05, 2015\n",
      "ANALYZING ANALYZING  Mar 06, 2015\n",
      "ANALYZING ANALYZING  Mar 07, 2015\n",
      "ANALYZING ANALYZING  Mar 08, 2015\n",
      "ANALYZING ANALYZING  Mar 09, 2015\n",
      "ANALYZING ANALYZING  Mar 10, 2015\n",
      "ANALYZING ANALYZING  Mar 11, 2015\n",
      "ANALYZING ANALYZING  Mar 12, 2015\n",
      "ANALYZING ANALYZING  Mar 13, 2015\n",
      "ANALYZING ANALYZING  Mar 14, 2015\n",
      "ANALYZING ANALYZING  Mar 15, 2015\n",
      "ANALYZING ANALYZING  Mar 16, 2015\n",
      "ANALYZING ANALYZING  Mar 17, 2015\n",
      "ANALYZING ANALYZING  Mar 18, 2015\n",
      "ANALYZING ANALYZING  Mar 19, 2015\n",
      "ANALYZING ANALYZING  Mar 20, 2015\n",
      "ANALYZING ANALYZING  Mar 21, 2015\n",
      "ANALYZING ANALYZING  Mar 22, 2015\n",
      "ANALYZING ANALYZING  Mar 23, 2015\n",
      "ANALYZING ANALYZING  Mar 24, 2015\n",
      "ANALYZING ANALYZING  Mar 25, 2015\n",
      "ANALYZING ANALYZING  Mar 26, 2015\n",
      "ANALYZING ANALYZING  Mar 27, 2015\n",
      "ANALYZING ANALYZING  Mar 28, 2015\n",
      "ANALYZING ANALYZING  Mar 29, 2015\n",
      "ANALYZING ANALYZING  Mar 30, 2015\n",
      "ANALYZING ANALYZING  Mar 31, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-03-01'\n",
    "end = '2015-03-31'\n",
    "f = nc.Dataset('./mar_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Apr 01, 2015\n",
      "ANALYZING ANALYZING  Apr 02, 2015\n",
      "ANALYZING ANALYZING  Apr 03, 2015\n",
      "ANALYZING ANALYZING  Apr 04, 2015\n",
      "ANALYZING ANALYZING  Apr 05, 2015\n",
      "ANALYZING ANALYZING  Apr 06, 2015\n",
      "ANALYZING ANALYZING  Apr 07, 2015\n",
      "ANALYZING ANALYZING  Apr 08, 2015\n",
      "ANALYZING ANALYZING  Apr 09, 2015\n",
      "ANALYZING ANALYZING  Apr 10, 2015\n",
      "ANALYZING ANALYZING  Apr 11, 2015\n",
      "ANALYZING ANALYZING  Apr 12, 2015\n",
      "ANALYZING ANALYZING  Apr 13, 2015\n",
      "ANALYZING ANALYZING  Apr 14, 2015\n",
      "ANALYZING ANALYZING  Apr 15, 2015\n",
      "ANALYZING ANALYZING  Apr 16, 2015\n",
      "ANALYZING ANALYZING  Apr 17, 2015\n",
      "ANALYZING ANALYZING  Apr 18, 2015\n",
      "ANALYZING ANALYZING  Apr 19, 2015\n",
      "ANALYZING ANALYZING  Apr 20, 2015\n",
      "ANALYZING ANALYZING  Apr 21, 2015\n",
      "ANALYZING ANALYZING  Apr 22, 2015\n",
      "ANALYZING ANALYZING  Apr 23, 2015\n",
      "ANALYZING ANALYZING  Apr 24, 2015\n",
      "ANALYZING ANALYZING  Apr 25, 2015\n",
      "ANALYZING ANALYZING  Apr 26, 2015\n",
      "ANALYZING ANALYZING  Apr 27, 2015\n",
      "ANALYZING ANALYZING  Apr 28, 2015\n",
      "ANALYZING ANALYZING  Apr 29, 2015\n",
      "ANALYZING ANALYZING  Apr 30, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-04-01'\n",
    "end = '2015-04-30'\n",
    "f = nc.Dataset('./apr_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  May 01, 2015\n",
      "ANALYZING ANALYZING  May 02, 2015\n",
      "ANALYZING ANALYZING  May 03, 2015\n",
      "ANALYZING ANALYZING  May 04, 2015\n",
      "ANALYZING ANALYZING  May 05, 2015\n",
      "ANALYZING ANALYZING  May 06, 2015\n",
      "ANALYZING ANALYZING  May 07, 2015\n",
      "ANALYZING ANALYZING  May 08, 2015\n",
      "ANALYZING ANALYZING  May 09, 2015\n",
      "ANALYZING ANALYZING  May 10, 2015\n",
      "ANALYZING ANALYZING  May 11, 2015\n",
      "ANALYZING ANALYZING  May 12, 2015\n",
      "ANALYZING ANALYZING  May 13, 2015\n",
      "ANALYZING ANALYZING  May 14, 2015\n",
      "ANALYZING ANALYZING  May 15, 2015\n",
      "ANALYZING ANALYZING  May 16, 2015\n",
      "ANALYZING ANALYZING  May 17, 2015\n",
      "ANALYZING ANALYZING  May 18, 2015\n",
      "ANALYZING ANALYZING  May 19, 2015\n",
      "ANALYZING ANALYZING  May 20, 2015\n",
      "ANALYZING ANALYZING  May 21, 2015\n",
      "ANALYZING ANALYZING  May 22, 2015\n",
      "ANALYZING ANALYZING  May 23, 2015\n",
      "ANALYZING ANALYZING  May 24, 2015\n",
      "ANALYZING ANALYZING  May 25, 2015\n",
      "ANALYZING ANALYZING  May 26, 2015\n",
      "ANALYZING ANALYZING  May 27, 2015\n",
      "ANALYZING ANALYZING  May 28, 2015\n",
      "ANALYZING ANALYZING  May 29, 2015\n",
      "ANALYZING ANALYZING  May 30, 2015\n",
      "ANALYZING ANALYZING  May 31, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-05-01'\n",
    "end = '2015-05-31'\n",
    "f = nc.Dataset('./may_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Jun 01, 2015\n",
      "ANALYZING ANALYZING  Jun 02, 2015\n",
      "ANALYZING ANALYZING  Jun 03, 2015\n",
      "ANALYZING ANALYZING  Jun 04, 2015\n",
      "ANALYZING ANALYZING  Jun 05, 2015\n",
      "ANALYZING ANALYZING  Jun 06, 2015\n",
      "ANALYZING ANALYZING  Jun 07, 2015\n",
      "ANALYZING ANALYZING  Jun 08, 2015\n",
      "ANALYZING ANALYZING  Jun 09, 2015\n",
      "ANALYZING ANALYZING  Jun 10, 2015\n",
      "ANALYZING ANALYZING  Jun 11, 2015\n",
      "ANALYZING ANALYZING  Jun 12, 2015\n",
      "ANALYZING ANALYZING  Jun 13, 2015\n",
      "ANALYZING ANALYZING  Jun 14, 2015\n",
      "ANALYZING ANALYZING  Jun 15, 2015\n",
      "ANALYZING ANALYZING  Jun 16, 2015\n",
      "ANALYZING ANALYZING  Jun 17, 2015\n",
      "ANALYZING ANALYZING  Jun 18, 2015\n",
      "ANALYZING ANALYZING  Jun 19, 2015\n",
      "ANALYZING ANALYZING  Jun 20, 2015\n",
      "ANALYZING ANALYZING  Jun 21, 2015\n",
      "ANALYZING ANALYZING  Jun 22, 2015\n",
      "ANALYZING ANALYZING  Jun 23, 2015\n",
      "ANALYZING ANALYZING  Jun 24, 2015\n",
      "ANALYZING ANALYZING  Jun 25, 2015\n",
      "ANALYZING ANALYZING  Jun 26, 2015\n",
      "ANALYZING ANALYZING  Jun 27, 2015\n",
      "ANALYZING ANALYZING  Jun 28, 2015\n",
      "ANALYZING ANALYZING  Jun 29, 2015\n",
      "ANALYZING ANALYZING  Jun 30, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-06-01'\n",
    "end = '2015-06-30'\n",
    "f = nc.Dataset('./jun_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Jul 01, 2015\n",
      "ANALYZING ANALYZING  Jul 02, 2015\n",
      "ANALYZING ANALYZING  Jul 03, 2015\n",
      "ANALYZING ANALYZING  Jul 04, 2015\n",
      "ANALYZING ANALYZING  Jul 05, 2015\n",
      "ANALYZING ANALYZING  Jul 06, 2015\n",
      "ANALYZING ANALYZING  Jul 07, 2015\n",
      "ANALYZING ANALYZING  Jul 08, 2015\n",
      "ANALYZING ANALYZING  Jul 09, 2015\n",
      "ANALYZING ANALYZING  Jul 10, 2015\n",
      "ANALYZING ANALYZING  Jul 11, 2015\n",
      "ANALYZING ANALYZING  Jul 12, 2015\n",
      "ANALYZING ANALYZING  Jul 13, 2015\n",
      "ANALYZING ANALYZING  Jul 14, 2015\n",
      "ANALYZING ANALYZING  Jul 15, 2015\n",
      "ANALYZING ANALYZING  Jul 16, 2015\n",
      "ANALYZING ANALYZING  Jul 17, 2015\n",
      "ANALYZING ANALYZING  Jul 18, 2015\n",
      "ANALYZING ANALYZING  Jul 19, 2015\n",
      "ANALYZING ANALYZING  Jul 20, 2015\n",
      "ANALYZING ANALYZING  Jul 21, 2015\n",
      "ANALYZING ANALYZING  Jul 22, 2015\n",
      "ANALYZING ANALYZING  Jul 23, 2015\n",
      "ANALYZING ANALYZING  Jul 24, 2015\n",
      "ANALYZING ANALYZING  Jul 25, 2015\n",
      "ANALYZING ANALYZING  Jul 26, 2015\n",
      "ANALYZING ANALYZING  Jul 27, 2015\n",
      "ANALYZING ANALYZING  Jul 28, 2015\n",
      "ANALYZING ANALYZING  Jul 29, 2015\n",
      "ANALYZING ANALYZING  Jul 30, 2015\n",
      "ANALYZING ANALYZING  Jul 31, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-07-01'\n",
    "end = '2015-07-31'\n",
    "f = nc.Dataset('./jul_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Aug 01, 2015\n",
      "ANALYZING ANALYZING  Aug 02, 2015\n",
      "ANALYZING ANALYZING  Aug 03, 2015\n",
      "ANALYZING ANALYZING  Aug 04, 2015\n",
      "ANALYZING ANALYZING  Aug 05, 2015\n",
      "ANALYZING ANALYZING  Aug 06, 2015\n",
      "ANALYZING ANALYZING  Aug 07, 2015\n",
      "ANALYZING ANALYZING  Aug 08, 2015\n",
      "ANALYZING ANALYZING  Aug 09, 2015\n",
      "ANALYZING ANALYZING  Aug 10, 2015\n",
      "ANALYZING ANALYZING  Aug 11, 2015\n",
      "ANALYZING ANALYZING  Aug 12, 2015\n",
      "ANALYZING ANALYZING  Aug 13, 2015\n",
      "ANALYZING ANALYZING  Aug 14, 2015\n",
      "ANALYZING ANALYZING  Aug 15, 2015\n",
      "ANALYZING ANALYZING  Aug 16, 2015\n",
      "ANALYZING ANALYZING  Aug 17, 2015\n",
      "ANALYZING ANALYZING  Aug 18, 2015\n",
      "ANALYZING ANALYZING  Aug 19, 2015\n",
      "ANALYZING ANALYZING  Aug 20, 2015\n",
      "ANALYZING ANALYZING  Aug 21, 2015\n",
      "ANALYZING ANALYZING  Aug 22, 2015\n",
      "ANALYZING ANALYZING  Aug 23, 2015\n",
      "ANALYZING ANALYZING  Aug 24, 2015\n",
      "ANALYZING ANALYZING  Aug 25, 2015\n",
      "ANALYZING ANALYZING  Aug 26, 2015\n",
      "ANALYZING ANALYZING  Aug 27, 2015\n",
      "ANALYZING ANALYZING  Aug 28, 2015\n",
      "ANALYZING ANALYZING  Aug 29, 2015\n",
      "ANALYZING ANALYZING  Aug 30, 2015\n",
      "ANALYZING ANALYZING  Aug 31, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-08-01'\n",
    "end = '2015-08-31'\n",
    "f = nc.Dataset('./aug_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Sep 01, 2015\n",
      "ANALYZING ANALYZING  Sep 02, 2015\n",
      "ANALYZING ANALYZING  Sep 03, 2015\n",
      "ANALYZING ANALYZING  Sep 04, 2015\n",
      "ANALYZING ANALYZING  Sep 05, 2015\n",
      "ANALYZING ANALYZING  Sep 06, 2015\n",
      "ANALYZING ANALYZING  Sep 07, 2015\n",
      "ANALYZING ANALYZING  Sep 08, 2015\n",
      "ANALYZING ANALYZING  Sep 09, 2015\n",
      "ANALYZING ANALYZING  Sep 10, 2015\n",
      "ANALYZING ANALYZING  Sep 11, 2015\n",
      "ANALYZING ANALYZING  Sep 12, 2015\n",
      "ANALYZING ANALYZING  Sep 13, 2015\n",
      "ANALYZING ANALYZING  Sep 14, 2015\n",
      "ANALYZING ANALYZING  Sep 15, 2015\n",
      "ANALYZING ANALYZING  Sep 16, 2015\n",
      "ANALYZING ANALYZING  Sep 17, 2015\n",
      "ANALYZING ANALYZING  Sep 18, 2015\n",
      "ANALYZING ANALYZING  Sep 19, 2015\n",
      "ANALYZING ANALYZING  Sep 20, 2015\n",
      "ANALYZING ANALYZING  Sep 21, 2015\n",
      "ANALYZING ANALYZING  Sep 22, 2015\n",
      "ANALYZING ANALYZING  Sep 23, 2015\n",
      "ANALYZING ANALYZING  Sep 24, 2015\n",
      "ANALYZING ANALYZING  Sep 25, 2015\n",
      "ANALYZING ANALYZING  Sep 26, 2015\n",
      "ANALYZING ANALYZING  Sep 27, 2015\n",
      "ANALYZING ANALYZING  Sep 28, 2015\n",
      "ANALYZING ANALYZING  Sep 29, 2015\n",
      "ANALYZING ANALYZING  Sep 30, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-09-01'\n",
    "end = '2015-09-30'\n",
    "f = nc.Dataset('./sep_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Oct 01, 2015\n",
      "ANALYZING ANALYZING  Oct 02, 2015\n",
      "ANALYZING ANALYZING  Oct 03, 2015\n",
      "ANALYZING ANALYZING  Oct 04, 2015\n",
      "ANALYZING ANALYZING  Oct 05, 2015\n",
      "ANALYZING ANALYZING  Oct 06, 2015\n",
      "ANALYZING ANALYZING  Oct 07, 2015\n",
      "ANALYZING ANALYZING  Oct 08, 2015\n",
      "ANALYZING ANALYZING  Oct 09, 2015\n",
      "ANALYZING ANALYZING  Oct 10, 2015\n",
      "ANALYZING ANALYZING  Oct 11, 2015\n",
      "ANALYZING ANALYZING  Oct 12, 2015\n",
      "ANALYZING ANALYZING  Oct 13, 2015\n",
      "ANALYZING ANALYZING  Oct 14, 2015\n",
      "ANALYZING ANALYZING  Oct 15, 2015\n",
      "ANALYZING ANALYZING  Oct 16, 2015\n",
      "ANALYZING ANALYZING  Oct 17, 2015\n",
      "ANALYZING ANALYZING  Oct 18, 2015\n",
      "ANALYZING ANALYZING  Oct 19, 2015\n",
      "ANALYZING ANALYZING  Oct 20, 2015\n",
      "ANALYZING ANALYZING  Oct 21, 2015\n",
      "ANALYZING ANALYZING  Oct 22, 2015\n",
      "ANALYZING ANALYZING  Oct 23, 2015\n",
      "ANALYZING ANALYZING  Oct 24, 2015\n",
      "ANALYZING ANALYZING  Oct 25, 2015\n",
      "ANALYZING ANALYZING  Oct 26, 2015\n",
      "ANALYZING ANALYZING  Oct 27, 2015\n",
      "ANALYZING ANALYZING  Oct 28, 2015\n",
      "ANALYZING ANALYZING  Oct 29, 2015\n",
      "ANALYZING ANALYZING  Oct 30, 2015\n",
      "ANALYZING ANALYZING  Oct 31, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-10-01'\n",
    "end = '2015-10-31'\n",
    "f = nc.Dataset('./oct_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Nov 01, 2015\n",
      "ANALYZING ANALYZING  Nov 02, 2015\n",
      "ANALYZING ANALYZING  Nov 03, 2015\n",
      "ANALYZING ANALYZING  Nov 04, 2015\n",
      "ANALYZING ANALYZING  Nov 05, 2015\n",
      "ANALYZING ANALYZING  Nov 06, 2015\n",
      "ANALYZING ANALYZING  Nov 07, 2015\n",
      "ANALYZING ANALYZING  Nov 08, 2015\n",
      "ANALYZING ANALYZING  Nov 09, 2015\n",
      "ANALYZING ANALYZING  Nov 10, 2015\n",
      "ANALYZING ANALYZING  Nov 11, 2015\n",
      "ANALYZING ANALYZING  Nov 12, 2015\n",
      "ANALYZING ANALYZING  Nov 13, 2015\n",
      "ANALYZING ANALYZING  Nov 14, 2015\n",
      "ANALYZING ANALYZING  Nov 15, 2015\n",
      "ANALYZING ANALYZING  Nov 16, 2015\n",
      "ANALYZING ANALYZING  Nov 17, 2015\n",
      "ANALYZING ANALYZING  Nov 18, 2015\n",
      "ANALYZING ANALYZING  Nov 19, 2015\n",
      "ANALYZING ANALYZING  Nov 20, 2015\n",
      "ANALYZING ANALYZING  Nov 21, 2015\n",
      "ANALYZING ANALYZING  Nov 22, 2015\n",
      "ANALYZING ANALYZING  Nov 23, 2015\n",
      "ANALYZING ANALYZING  Nov 24, 2015\n",
      "ANALYZING ANALYZING  Nov 25, 2015\n",
      "ANALYZING ANALYZING  Nov 26, 2015\n",
      "ANALYZING ANALYZING  Nov 27, 2015\n",
      "ANALYZING ANALYZING  Nov 28, 2015\n",
      "ANALYZING ANALYZING  Nov 29, 2015\n",
      "ANALYZING ANALYZING  Nov 30, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-11-01'\n",
    "end = '2015-11-30'\n",
    "f = nc.Dataset('./nov_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING ANALYZING  Dec 01, 2015\n",
      "ANALYZING ANALYZING  Dec 02, 2015\n",
      "ANALYZING ANALYZING  Dec 03, 2015\n",
      "ANALYZING ANALYZING  Dec 04, 2015\n",
      "ANALYZING ANALYZING  Dec 05, 2015\n",
      "ANALYZING ANALYZING  Dec 06, 2015\n",
      "ANALYZING ANALYZING  Dec 07, 2015\n",
      "ANALYZING ANALYZING  Dec 08, 2015\n",
      "ANALYZING ANALYZING  Dec 09, 2015\n",
      "ANALYZING ANALYZING  Dec 10, 2015\n",
      "ANALYZING ANALYZING  Dec 11, 2015\n",
      "ANALYZING ANALYZING  Dec 12, 2015\n",
      "ANALYZING ANALYZING  Dec 13, 2015\n",
      "ANALYZING ANALYZING  Dec 14, 2015\n",
      "ANALYZING ANALYZING  Dec 15, 2015\n",
      "ANALYZING ANALYZING  Dec 16, 2015\n",
      "ANALYZING ANALYZING  Dec 17, 2015\n",
      "ANALYZING ANALYZING  Dec 18, 2015\n",
      "ANALYZING ANALYZING  Dec 19, 2015\n",
      "ANALYZING ANALYZING  Dec 20, 2015\n",
      "ANALYZING ANALYZING  Dec 21, 2015\n",
      "ANALYZING ANALYZING  Dec 22, 2015\n",
      "ANALYZING ANALYZING  Dec 23, 2015\n",
      "ANALYZING ANALYZING  Dec 24, 2015\n",
      "ANALYZING ANALYZING  Dec 25, 2015\n",
      "ANALYZING ANALYZING  Dec 26, 2015\n",
      "ANALYZING ANALYZING  Dec 27, 2015\n",
      "ANALYZING ANALYZING  Dec 28, 2015\n",
      "ANALYZING ANALYZING  Dec 29, 2015\n",
      "ANALYZING ANALYZING  Dec 30, 2015\n",
      "ANALYZING ANALYZING  Dec 31, 2015\n"
     ]
    }
   ],
   "source": [
    "start = '2015-12-01'\n",
    "end = '2015-12-31'\n",
    "f = nc.Dataset('./dec_stored_PI_BR_output.nc','w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "arrow_array = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "DIC_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "DIC_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "TA_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "temp_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_BR_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "sal_PI_stor = np.zeros([len(arrow_array),40,898,398])\n",
    "\n",
    "\n",
    "for i in range(0,len(arrow_array)):\n",
    "    run_date = arrow_array[i][0]    \n",
    "    ddmmmyy = run_date.format('DDMMMYY').lower()\n",
    "    humandate = run_date.format('MMM DD, YYYY')\n",
    "    yyyymmdd = run_date.format('YYYYMMDD')\n",
    "    #if(i%5==0):\n",
    "    print('ANALYZING ANALYZING ',humandate)\n",
    "\n",
    "    #change this if you need to change strings\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/BR_2nd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_BR = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_BR=w['total_alkalinity'][:]\n",
    "    DIC_BR_stor[i,:,:,:] = DIC_BR\n",
    "    TA_BR_stor[i,:,:,:] = TA_BR\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_BR = w6['votemper'][0,:,:,:]\n",
    "    sal_BR = w6['vosaline'][:]\n",
    "    temp_BR_stor[i,:,:,:] = temp_BR\n",
    "    sal_BR_stor[i,:,:,:] = sal_BR\n",
    "\n",
    "    carp1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_carp_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    grid1 = f'/data/tjarniko/results/BASERUN_EXP/PI_3rd_2015/ncs/SKOG_1d_*_grid_T_{yyyymmdd}-{yyyymmdd}.nc'\n",
    "    w2 = glob.glob(carp1)\n",
    "    w3 = w2[0]\n",
    "    w = nc.Dataset(w3)\n",
    "    DIC_PI = w['dissolved_inorganic_carbon'][:]\n",
    "    TA_PI=w['total_alkalinity'][:]\n",
    "    DIC_PI_stor[i,:,:,:] = DIC_PI\n",
    "    TA_PI_stor[i,:,:,:] = TA_PI\n",
    "    w4 = glob.glob(grid1)\n",
    "    w5 = w4[0]\n",
    "    w6 = nc.Dataset(w5)\n",
    "    temp_PI = w6['votemper'][:]\n",
    "    sal_PI = w6['vosaline'][:]\n",
    "    temp_PI_stor[i,:,:,:] = temp_PI\n",
    "    sal_PI_stor[i,:,:,:] = sal_PI   \n",
    "\n",
    "g = f.createGroup('ncoutput')\n",
    "g.createDimension('day', len(arrow_array))\n",
    "g.createDimension('xval', 898)\n",
    "g.createDimension('yval', 398)\n",
    "g.createDimension('depth', 40)\n",
    "ts = g.createVariable('DIC_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_BR_stor \n",
    "ts = g.createVariable('DIC_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = DIC_PI_stor\n",
    "ts = g.createVariable('TA_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_BR_stor \n",
    "ts = g.createVariable('TA_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = TA_PI_stor  \n",
    "ts = g.createVariable('temp_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_BR_stor\n",
    "ts = g.createVariable('temp_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = temp_PI_stor\n",
    "ts = g.createVariable('sal_BR_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_BR_stor \n",
    "ts = g.createVariable('sal_PI_stor','f4',('day','depth','xval','yval'))\n",
    "ts[:] = sal_PI_stor\n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arrow\n",
    "import netCDF4 as nc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We partition these data into five seasons: winter (November–February), spring (March to mid-May), freshet\n",
    "(defined below), summer (mid-May to September), and fall (October–November), consistent with the largescale\n",
    "wind patterns responsible for upwelling/downwelling (Table S2) [Bylhouwer et al., 2013]. The transition to\n",
    "downwelling coincides with the first winter storms, which mix down the strong summer surface stratification\n",
    "in the SoG. Upwelling and downwelling on the outer coast directly influence the properties of the subsurface\n",
    "inflow in the JdF [M06; Davis et al., 2014]. The freshet “season” occurs within the summer season, in years\n",
    "when the Fraser outflow is strong enough to produce surface S < 20 at our sampling locations in the S-SoG\n",
    "(Figure 1; 2011 and 2012 in our data).\n",
    "\n",
    "#ben's extractor: https://github.com/SalishSeaCast/analysis-ben/blob/master/notebooks/master_hindcast_extractor.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dec-Feb, Mar-May, Jun-Aug, Sept-Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170301\n",
      "20170311\n",
      "20170321\n",
      "20170331\n",
      "20170410\n",
      "20170420\n",
      "20170430\n",
      "20170510\n",
      "20170520\n",
      "20170530\n"
     ]
    }
   ],
   "source": [
    "rel_depth = [0,10,18,24,26]\n",
    "yr = 2017\n",
    "start =f'{yr}-03-01'\n",
    "end =f'{yr}-05-31'\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "\n",
    "arrow_array = []\n",
    "strlist = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "dayslen = len(arrow_array)\n",
    "\n",
    "BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "for i in range(0,dayslen):\n",
    "\n",
    "    tdate = arrow_array[i][0]\n",
    "    ymd = tdate.format('YYYYMMDD')\n",
    "    # yy = tdate.format('YYYY')tt\n",
    "    # mm = tdate.format('MM')\n",
    "    # dd = tdate.format('DD')\n",
    "    # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(ymd)\n",
    "    tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "    t_pco2 = nc.Dataset(tstr)\n",
    "    t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "    BR_oma_summer[i,:,:,:] = t_Oma\n",
    "    \n",
    "pickle.dump(BR_oma_summer[:,0,:,:], open(f'./pkls/OmA_{yr}_SPR_D_0.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,10,:,:], open(f'./pkls/OmA_{yr}_SPR_D_10.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,18,:,:], open(f'./pkls/OmA_{yr}_SPR_D_18.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,24,:,:], open(f'./pkls/OmA_{yr}_SPR_D_24.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,26,:,:], open(f'./pkls/OmA_{yr}_SPR_D_26.pkl', 'wb'))\n",
    "\n",
    "# ### loop for extraction of results\n",
    "# start =f'{yr}-06-01'\n",
    "# end =f'{yr}-08-31'\n",
    "\n",
    "# start_run = arrow.get(start)\n",
    "# end_run = arrow.get(end)\n",
    "\n",
    "# arrow_array = []\n",
    "# strlist = []\n",
    "# for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "#     arrow_array.append(r)\n",
    "\n",
    "# dayslen = len(arrow_array)\n",
    "\n",
    "# BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "# for i in range(0,dayslen):\n",
    "\n",
    "#     tdate = arrow_array[i][0]\n",
    "#     ymd = tdate.format('YYYYMMDD')\n",
    "#     # yy = tdate.format('YYYY')tt\n",
    "#     # mm = tdate.format('MM')\n",
    "#     # dd = tdate.format('DD')\n",
    "#     # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "#     if i%10 == 0:\n",
    "#         print(ymd)\n",
    "#     tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "#     t_pco2 = nc.Dataset(tstr)\n",
    "#     t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "#     BR_oma_summer[i,:,:,:] = t_Oma\n",
    "    \n",
    "# pickle.dump(BR_oma_summer, open(f'./pkls/OmA_{yr}_SUM.pkl', 'wb'))\n",
    "\n",
    "\n",
    "### loop for extraction of results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170101\n",
      "20170220\n",
      "20170411\n",
      "20170531\n",
      "20170720\n",
      "20170908\n",
      "20171028\n",
      "20171217\n"
     ]
    }
   ],
   "source": [
    "rel_depth = [0,10,18,24,26]\n",
    "yr = 2017\n",
    "start =f'{yr}-01-01'\n",
    "end =f'{yr}-12-31'\n",
    "\n",
    "start_run = arrow.get(start)\n",
    "end_run = arrow.get(end)\n",
    "\n",
    "arrow_array = []\n",
    "strlist = []\n",
    "for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "    arrow_array.append(r)\n",
    "\n",
    "dayslen = len(arrow_array)\n",
    "\n",
    "BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "for i in range(0,dayslen):\n",
    "\n",
    "    tdate = arrow_array[i][0]\n",
    "    ymd = tdate.format('YYYYMMDD')\n",
    "    # yy = tdate.format('YYYY')tt\n",
    "    # mm = tdate.format('MM')\n",
    "    # dd = tdate.format('DD')\n",
    "    # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "    if i%50 == 0:\n",
    "        print(ymd)\n",
    "    tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "    t_pco2 = nc.Dataset(tstr)\n",
    "    t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "    BR_oma_summer[i,:,:,:] = t_Oma\n",
    "    \n",
    "pickle.dump(BR_oma_summer[:,0,:,:], open(f'./pkls/OmA_{yr}_FY_D_0.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,10,:,:], open(f'./pkls/OmA_{yr}_FY_D_10.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,18,:,:], open(f'./pkls/OmA_{yr}_FY_D_18.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,24,:,:], open(f'./pkls/OmA_{yr}_FY_D_24.pkl', 'wb'))\n",
    "pickle.dump(BR_oma_summer[:,26,:,:], open(f'./pkls/OmA_{yr}_FY_D_26.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.06295924154529\n"
     ]
    }
   ],
   "source": [
    "#getting depths\n",
    "w = nc.Dataset('/data/tjarniko/MEOPAR/grid/mesh_mask201702.nc')\n",
    "print(w['gdept_1d'][0,26])\n",
    "\n",
    "rel_depth = [0,10,18,24,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = strlist[0:2]\n",
    "\n",
    "\n",
    "w = xr.open_mfdataset(testlist[0])\n",
    "\n",
    "print(t_pco2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BR_oma_summer[:,24,350,250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tcl = '/ocean/tjarniko/MEOPAR/analysis_tereza/notebooks/CLUSTER_PAPER/CLEAN/KEY_PAPERFIGURES/pkls/BIO_clno_5_2015_reass.pkl'\n",
    "xs_pkl = '/ocean/tjarniko/MEOPAR/analysis_tereza/notebooks/CLUSTER_PAPER/CLEAN/KEY_PAPERFIGURES/pkls/Xcoords_for571_stations.pkl'\n",
    "ys_pkl = '/ocean/tjarniko/MEOPAR/analysis_tereza/notebooks/CLUSTER_PAPER/CLEAN/KEY_PAPERFIGURES/pkls/Ycoords_for571_stations.pkl'\n",
    "\n",
    "cldes = pickle.load(open(tcl, 'rb'))\n",
    "xs = pickle.load(open(xs_pkl, 'rb'))\n",
    "ys = pickle.load(open(ys_pkl, 'rb'))\n",
    "\n",
    "ys_csog = ys[cldes == 3]\n",
    "print(ys_csog)\n",
    "xs_csog = xs[cldes == 3]\n",
    "print(xs_csog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(cldes_2015_reass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "q = xr.open_mfdataset(strlist, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_depth_avgs_no_loop(flist):\n",
    "    with nc.Dataset(flist) as ds:\n",
    "        print(ds)\n",
    "#         diatoms = ds.variables['diatoms'][:,:,j0:j1,i0:i1]\n",
    "#         diatoms_int = (diatoms * tmask * e3t0).sum(axis=1).mean(axis=0)\n",
    "#         uZ = ds.variables['microzooplankton'][:,:,j0:j1,i0:i1]\n",
    "#         uZ_int = (uZ * tmask * e3t0).sum(axis=1).mean(axis=0)\n",
    "    return ds\n",
    "\n",
    "\n",
    "calc_depth_avgs_no_loop(strlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

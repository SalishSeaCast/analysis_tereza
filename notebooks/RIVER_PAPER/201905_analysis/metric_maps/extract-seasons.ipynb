{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import arrow\n",
    "import netCDF4 as nc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We partition these data into five seasons: winter (November–February), spring (March to mid-May), freshet\n",
    "(defined below), summer (mid-May to September), and fall (October–November), consistent with the largescale\n",
    "wind patterns responsible for upwelling/downwelling (Table S2) [Bylhouwer et al., 2013]. The transition to\n",
    "downwelling coincides with the first winter storms, which mix down the strong summer surface stratification\n",
    "in the SoG. Upwelling and downwelling on the outer coast directly influence the properties of the subsurface\n",
    "inflow in the JdF [M06; Davis et al., 2014]. The freshet “season” occurs within the summer season, in years\n",
    "when the Fraser outflow is strong enough to produce surface S < 20 at our sampling locations in the S-SoG\n",
    "(Figure 1; 2011 and 2012 in our data).\n",
    "\n",
    "#ben's extractor: https://github.com/SalishSeaCast/analysis-ben/blob/master/notebooks/master_hindcast_extractor.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dec-Feb, Mar-May, Jun-Aug, Sept-Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "20130101\n",
      "20130111\n",
      "20130121\n",
      "20130131\n",
      "20130210\n",
      "20130220\n",
      "20130302\n",
      "20130312\n",
      "20130322\n",
      "20130401\n",
      "20130411\n",
      "20130421\n",
      "20130501\n",
      "20130511\n",
      "20130521\n",
      "20130531\n",
      "20130610\n",
      "20130620\n",
      "20130630\n",
      "20130710\n",
      "20130720\n",
      "20130730\n",
      "20130809\n",
      "20130819\n",
      "20130829\n",
      "20130908\n",
      "20130918\n",
      "20130928\n",
      "20131008\n",
      "20131018\n",
      "20131028\n",
      "20131107\n",
      "20131117\n",
      "20131127\n",
      "20131207\n",
      "20131217\n",
      "20131227\n",
      "2014\n",
      "20140101\n",
      "20140111\n",
      "20140121\n",
      "20140131\n",
      "20140210\n",
      "20140220\n",
      "20140302\n",
      "20140312\n",
      "20140322\n",
      "20140401\n",
      "20140411\n",
      "20140421\n",
      "20140501\n",
      "20140511\n",
      "20140521\n",
      "20140531\n",
      "20140610\n",
      "20140620\n",
      "20140630\n",
      "20140710\n",
      "20140720\n",
      "20140730\n",
      "20140809\n",
      "20140819\n",
      "20140829\n",
      "20140908\n",
      "20140918\n",
      "20140928\n",
      "20141008\n",
      "20141018\n",
      "20141028\n",
      "20141107\n",
      "20141117\n",
      "20141127\n",
      "20141207\n",
      "20141217\n",
      "20141227\n",
      "2015\n",
      "20150101\n",
      "20150111\n",
      "20150121\n",
      "20150131\n",
      "20150210\n",
      "20150220\n",
      "20150302\n",
      "20150312\n",
      "20150322\n",
      "20150401\n",
      "20150411\n",
      "20150421\n",
      "20150501\n",
      "20150511\n",
      "20150521\n",
      "20150531\n",
      "20150610\n",
      "20150620\n",
      "20150630\n",
      "20150710\n",
      "20150720\n",
      "20150730\n",
      "20150809\n",
      "20150819\n",
      "20150829\n",
      "20150908\n",
      "20150918\n",
      "20150928\n",
      "20151008\n",
      "20151018\n",
      "20151028\n",
      "20151107\n",
      "20151117\n",
      "20151127\n",
      "20151207\n",
      "20151217\n",
      "20151227\n",
      "2017\n",
      "20170101\n",
      "20170111\n",
      "20170121\n",
      "20170131\n",
      "20170210\n",
      "20170220\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c0989548805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mt_pco2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mt_Oma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_pco2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OmA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mBR_oma_summer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_Oma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._toma\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# yrs = ([2013,2014,2015,2017])\n",
    "\n",
    "# for yr in yrs:\n",
    "#     print(yr)\n",
    "#     rel_depth = [0,10,18,24,26]\n",
    "#     start =f'{yr}-01-01'\n",
    "#     end =f'{yr}-12-31'\n",
    "\n",
    "#     start_run = arrow.get(start)\n",
    "#     end_run = arrow.get(end)\n",
    "\n",
    "#     arrow_array = []\n",
    "#     strlist = []\n",
    "#     for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "#         arrow_array.append(r)\n",
    "\n",
    "#     dayslen = len(arrow_array)\n",
    "\n",
    "#     BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "#     for i in range(0,dayslen):\n",
    "\n",
    "#         tdate = arrow_array[i][0]\n",
    "#         ymd = tdate.format('YYYYMMDD')\n",
    "#         # yy = tdate.format('YYYY')tt\n",
    "#         # mm = tdate.format('MM')\n",
    "#         # dd = tdate.format('DD')\n",
    "#         # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "#         if i%10 == 0:\n",
    "#             print(ymd)\n",
    "#         tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "#         t_pco2 = nc.Dataset(tstr)\n",
    "#         t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "#         BR_oma_summer[i,:,:,:] = t_Oma\n",
    "\n",
    "#     pickle.dump(BR_oma_summer[:,0,:,:], open(f'./pkls/OmA_{yr}_FY_D_0.pkl', 'wb'))\n",
    "#     pickle.dump(BR_oma_summer[:,10,:,:], open(f'./pkls/OmA_{yr}_FY_D_10.pkl', 'wb'))\n",
    "#     pickle.dump(BR_oma_summer[:,18,:,:], open(f'./pkls/OmA_{yr}_FY_D_18.pkl', 'wb'))\n",
    "#     pickle.dump(BR_oma_summer[:,24,:,:], open(f'./pkls/OmA_{yr}_FY_D_24.pkl', 'wb'))\n",
    "#     pickle.dump(BR_oma_summer[:,26,:,:], open(f'./pkls/OmA_{yr}_FY_D_26.pkl', 'wb'))\n",
    "\n",
    "# # ### loop for extraction of results\n",
    "# # start =f'{yr}-06-01'\n",
    "# # end =f'{yr}-08-31'\n",
    "\n",
    "# # start_run = arrow.get(start)\n",
    "# # end_run = arrow.get(end)\n",
    "\n",
    "# # arrow_array = []\n",
    "# # strlist = []\n",
    "# # for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "# #     arrow_array.append(r)\n",
    "\n",
    "# # dayslen = len(arrow_array)\n",
    "\n",
    "# # BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "# # for i in range(0,dayslen):\n",
    "\n",
    "# #     tdate = arrow_array[i][0]\n",
    "# #     ymd = tdate.format('YYYYMMDD')\n",
    "# #     # yy = tdate.format('YYYY')tt\n",
    "# #     # mm = tdate.format('MM')\n",
    "# #     # dd = tdate.format('DD')\n",
    "# #     # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "# #     if i%10 == 0:\n",
    "# #         print(ymd)\n",
    "# #     tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "# #     t_pco2 = nc.Dataset(tstr)\n",
    "# #     t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "# #     BR_oma_summer[i,:,:,:] = t_Oma\n",
    "    \n",
    "# # pickle.dump(BR_oma_summer, open(f'./pkls/OmA_{yr}_SUM.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# ### loop for extraction of results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160101\n",
      "20160220\n",
      "20160410\n",
      "20160530\n",
      "20160719\n",
      "20160907\n",
      "20161027\n",
      "20161216\n"
     ]
    }
   ],
   "source": [
    "# rel_depth = [0,10,18,24,26]\n",
    "# yr = 2016\n",
    "# start =f'{yr}-01-01'\n",
    "# end =f'{yr}-12-30'\n",
    "\n",
    "# start_run = arrow.get(start)\n",
    "# end_run = arrow.get(end)\n",
    "\n",
    "# arrow_array = []\n",
    "# strlist = []\n",
    "# for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "#     arrow_array.append(r)\n",
    "\n",
    "# dayslen = len(arrow_array)\n",
    "\n",
    "# BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "# for i in range(0,dayslen):\n",
    "\n",
    "#     tdate = arrow_array[i][0]\n",
    "#     ymd = tdate.format('YYYYMMDD')\n",
    "#     # yy = tdate.format('YYYY')tt\n",
    "#     # mm = tdate.format('MM')\n",
    "#     # dd = tdate.format('DD')\n",
    "#     # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "#     if i%50 == 0:\n",
    "#         print(ymd)\n",
    "#     tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "#     t_pco2 = nc.Dataset(tstr)\n",
    "#     t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "#     BR_oma_summer[i,:,:,:] = t_Oma\n",
    "    \n",
    "# pickle.dump(BR_oma_summer[:,0,:,:], open(f'./pkls/OmA_{yr}_FY_D_0.pkl', 'wb'))\n",
    "# pickle.dump(BR_oma_summer[:,10,:,:], open(f'./pkls/OmA_{yr}_FY_D_10.pkl', 'wb'))\n",
    "# pickle.dump(BR_oma_summer[:,18,:,:], open(f'./pkls/OmA_{yr}_FY_D_18.pkl', 'wb'))\n",
    "# pickle.dump(BR_oma_summer[:,24,:,:], open(f'./pkls/OmA_{yr}_FY_D_24.pkl', 'wb'))\n",
    "# pickle.dump(BR_oma_summer[:,26,:,:], open(f'./pkls/OmA_{yr}_FY_D_26.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "20170101\n",
      "20170111\n",
      "20170121\n",
      "20170131\n",
      "20170210\n",
      "20170220\n",
      "20170302\n",
      "20170312\n",
      "20170322\n",
      "20170401\n",
      "20170411\n",
      "20170421\n",
      "20170501\n",
      "20170511\n",
      "20170521\n",
      "20170531\n",
      "20170610\n",
      "20170620\n",
      "20170630\n",
      "20170710\n",
      "20170720\n",
      "20170730\n",
      "20170809\n",
      "20170819\n",
      "20170829\n",
      "20170908\n",
      "20170918\n",
      "20170928\n",
      "20171008\n",
      "20171018\n",
      "20171028\n",
      "20171107\n",
      "20171117\n",
      "20171127\n",
      "20171207\n",
      "20171217\n",
      "20171227\n"
     ]
    }
   ],
   "source": [
    "yrs = ([2017])\n",
    "\n",
    "for yr in yrs:\n",
    "    print(yr)\n",
    "    rel_depth = [0,10,18,24,26]\n",
    "    start =f'{yr}-01-01'\n",
    "    end =f'{yr}-12-31'\n",
    "\n",
    "    start_run = arrow.get(start)\n",
    "    end_run = arrow.get(end)\n",
    "\n",
    "    arrow_array = []\n",
    "    strlist = []\n",
    "    for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "        arrow_array.append(r)\n",
    "\n",
    "    dayslen = len(arrow_array)\n",
    "\n",
    "    BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "    for i in range(0,dayslen):\n",
    "\n",
    "        tdate = arrow_array[i][0]\n",
    "        ymd = tdate.format('YYYYMMDD')\n",
    "        # yy = tdate.format('YYYY')tt\n",
    "        # mm = tdate.format('MM')\n",
    "        # dd = tdate.format('DD')\n",
    "        # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print(ymd)\n",
    "        tstr = f'/data/tjarniko/results/BASERUN_EXP/Oma_calc/CAR50_4_OmA_plus_{ymd}.nc'\n",
    "        t_pco2 = nc.Dataset(tstr)\n",
    "        t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "        BR_oma_summer[i,:,:,:] = t_Oma\n",
    "\n",
    "    pickle.dump(BR_oma_summer[:,0,:,:], open(f'./pkls/CAR50_4_OmA_{yr}_FY_D_0.pkl', 'wb'))\n",
    "    pickle.dump(BR_oma_summer[:,10,:,:], open(f'./pkls/CAR50_4_OmA_{yr}_FY_D_10.pkl', 'wb'))\n",
    "    pickle.dump(BR_oma_summer[:,18,:,:], open(f'./pkls/CAR50_4_OmA_{yr}_FY_D_18.pkl', 'wb'))\n",
    "    pickle.dump(BR_oma_summer[:,24,:,:], open(f'./pkls/CAR50_4_OmA_{yr}_FY_D_24.pkl', 'wb'))\n",
    "    pickle.dump(BR_oma_summer[:,26,:,:], open(f'./pkls/CAR50_4_OmA_{yr}_FY_D_26.pkl', 'wb'))\n",
    "\n",
    "# ### loop for extraction of results\n",
    "# start =f'{yr}-06-01'\n",
    "# end =f'{yr}-08-31'\n",
    "\n",
    "# start_run = arrow.get(start)\n",
    "# end_run = arrow.get(end)\n",
    "\n",
    "# arrow_array = []\n",
    "# strlist = []\n",
    "# for r in arrow.Arrow.span_range('day', start_run, end_run):\n",
    "#     arrow_array.append(r)\n",
    "\n",
    "# dayslen = len(arrow_array)\n",
    "\n",
    "# BR_oma_summer = np.zeros([dayslen,40,898,398])\n",
    "\n",
    "# for i in range(0,dayslen):\n",
    "\n",
    "#     tdate = arrow_array[i][0]\n",
    "#     ymd = tdate.format('YYYYMMDD')\n",
    "#     # yy = tdate.format('YYYY')tt\n",
    "#     # mm = tdate.format('MM')\n",
    "#     # dd = tdate.format('DD')\n",
    "#     # ymd = f'{yy}m{mm}d{dd}.nc'\n",
    "\n",
    "#     if i%10 == 0:\n",
    "#         print(ymd)\n",
    "#     tstr = f'/data/tjarniko/results/hindcast.201905_dayavg_OmA-pH-pCO2/OmA_plus_{ymd}.nc'\n",
    "#     t_pco2 = nc.Dataset(tstr)\n",
    "#     t_Oma = t_pco2['model_output']['OmA'][:,:,:]\n",
    "#     BR_oma_summer[i,:,:,:] = t_Oma\n",
    "    \n",
    "# pickle.dump(BR_oma_summer, open(f'./pkls/OmA_{yr}_SUM.pkl', 'wb'))\n",
    "\n",
    "\n",
    "### loop for extraction of results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting depths\n",
    "w = nc.Dataset('/data/tjarniko/MEOPAR/grid/mesh_mask201702.nc')\n",
    "print(w['gdept_1d'][0,26])\n",
    "\n",
    "rel_depth = [0,10,18,24,26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = strlist[0:2]\n",
    "\n",
    "\n",
    "w = xr.open_mfdataset(testlist[0])\n",
    "\n",
    "print(t_pco2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BR_oma_summer[:,24,350,250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tcl = '/ocean/tjarniko/MEOPAR/analysis_tereza/notebooks/CLUSTER_PAPER/CLEAN/KEY_PAPERFIGURES/pkls/BIO_clno_5_2015_reass.pkl'\n",
    "xs_pkl = '/ocean/tjarniko/MEOPAR/analysis_tereza/notebooks/CLUSTER_PAPER/CLEAN/KEY_PAPERFIGURES/pkls/Xcoords_for571_stations.pkl'\n",
    "ys_pkl = '/ocean/tjarniko/MEOPAR/analysis_tereza/notebooks/CLUSTER_PAPER/CLEAN/KEY_PAPERFIGURES/pkls/Ycoords_for571_stations.pkl'\n",
    "\n",
    "cldes = pickle.load(open(tcl, 'rb'))\n",
    "xs = pickle.load(open(xs_pkl, 'rb'))\n",
    "ys = pickle.load(open(ys_pkl, 'rb'))\n",
    "\n",
    "ys_csog = ys[cldes == 3]\n",
    "print(ys_csog)\n",
    "xs_csog = xs[cldes == 3]\n",
    "print(xs_csog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(cldes_2015_reass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "q = xr.open_mfdataset(strlist, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_depth_avgs_no_loop(flist):\n",
    "    with nc.Dataset(flist) as ds:\n",
    "        print(ds)\n",
    "#         diatoms = ds.variables['diatoms'][:,:,j0:j1,i0:i1]\n",
    "#         diatoms_int = (diatoms * tmask * e3t0).sum(axis=1).mean(axis=0)\n",
    "#         uZ = ds.variables['microzooplankton'][:,:,j0:j1,i0:i1]\n",
    "#         uZ_int = (uZ * tmask * e3t0).sum(axis=1).mean(axis=0)\n",
    "    return ds\n",
    "\n",
    "\n",
    "calc_depth_avgs_no_loop(strlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
